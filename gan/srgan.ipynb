{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Generator, Union\n",
    "from tensorflow import Tensor, GradientTape, function, concat, ones, zeros, random, cast, constant\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, add, Input, UpSampling2D, LeakyReLU, Dense, PReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def generator_net(input_shape: tuple, res_num: int = 1) -> Model:\n",
    "    \"\"\"\n",
    "    Srgan生成器网络\n",
    "\n",
    "    :param input_shape: 输入图像形状\n",
    "    :param res_num: 残差块个数\n",
    "    :return: 生成器网络\n",
    "    \"\"\"\n",
    "\n",
    "    def res_block(y_) -> Tensor:\n",
    "        \"\"\"\n",
    "        残差网络块\n",
    "\n",
    "        :param y_: 输入\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for i in range(res_num):\n",
    "            _y = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(y_)\n",
    "            _y = BatchNormalization()(_y)\n",
    "            _y = PReLU()(_y)\n",
    "            _y = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(_y)\n",
    "            _y = BatchNormalization()(_y)\n",
    "            y_ = add([_y, y_])\n",
    "        return y_\n",
    "\n",
    "    x = Input(shape=input_shape)\n",
    "\n",
    "    # head\n",
    "    y = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "    y = PReLU()(y)\n",
    "\n",
    "    # body\n",
    "    y_ = res_block(y)\n",
    "\n",
    "    y_ = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(y_)\n",
    "    y_ = BatchNormalization()(y_)\n",
    "    y = add([y_, y])\n",
    "\n",
    "    # leg\n",
    "    y = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(y)\n",
    "    y = UpSampling2D(size=2)(y)\n",
    "    y = PReLU()(y)\n",
    "\n",
    "    y = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(y)\n",
    "    y = UpSampling2D(size=2)(y)\n",
    "    y = PReLU()(y)\n",
    "\n",
    "    y = Conv2D(filters=input_shape[-1], kernel_size=(3, 3), padding=\"same\")(y)\n",
    "    return Model(inputs=x, outputs=y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def discriminator_net(input_shape: tuple) -> Model:\n",
    "    \"\"\"\n",
    "    判决器网络\n",
    "\n",
    "    :param input_shape: 图片输入形状\n",
    "    :return: 判决器网络\n",
    "    \"\"\"\n",
    "    x = Input(shape=input_shape)\n",
    "\n",
    "    y = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "    y = LeakyReLU()(y)\n",
    "\n",
    "    y = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", strides=2)(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", strides=2)(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", strides=2)(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = Dense(512)(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Dense(1)(y)\n",
    "    y = sigmoid(y)\n",
    "    return Model(inputs=x, outputs=y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 64)   1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 32, 32, 64)   65536       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_5 (PReLU)               (None, 32, 32, 64)   65536       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "                                                                 p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 64)   36928       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
      "                                                                 p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 256)  147712      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 256)  0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_6 (PReLU)               (None, 64, 64, 256)  1048576     up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      p_re_lu_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_7 (PReLU)               (None, 128, 128, 256 4194304     up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 3)  6915        p_re_lu_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,232,003\n",
      "Trainable params: 6,231,619\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen = generator_net((32, 32, 3))\n",
    "gen_opt = Adam(learning_rate=0.0004)\n",
    "gen.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16, 16, 512)       131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16, 16, 1)         513       \n",
      "_________________________________________________________________\n",
      "tf.math.sigmoid_1 (TFOpLambd (None, 16, 16, 1)         0         \n",
      "=================================================================\n",
      "Total params: 541,633\n",
      "Trainable params: 540,737\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dis = discriminator_net((128, 128, 3))\n",
    "dis_opt = Adam(learning_rate=0.0003)\n",
    "dis.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def img_to_one(img: Union[Tensor, np.ndarray]):\n",
    "    \"\"\"\n",
    "    归一化\n",
    "\n",
    "    :param img:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return (img / 255. - 0.5) * 2.\n",
    "\n",
    "def reverse_img(img: Tensor):\n",
    "    \"\"\"\n",
    "    图片还原\n",
    "\n",
    "    :param img:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return cast((img + constant(1, dtype=\"float32\")) * 255 / 2, dtype=\"int32\")\n",
    "\n",
    "def data_loader(img_path: str, batch_size: int) -> Generator:\n",
    "    img_list = list(Path(img_path).iterdir())\n",
    "    batch_num = len(img_list) // batch_size\n",
    "    np.random.shuffle(img_list)\n",
    "    batch_hr_img_data = []\n",
    "    batch_lr_img_data = []\n",
    "    for num in range(0, batch_size * batch_num):\n",
    "        _img = cv2.cvtColor(cv2.resize(cv2.imread(str(img_list[num]), cv2.IMREAD_COLOR),\n",
    "                                       (128, 128)), cv2.COLOR_BGR2RGB)\n",
    "        batch_hr_img_data.append(_img)\n",
    "        batch_lr_img_data.append(cv2.resize(_img, (32, 32), cv2.INTER_LINEAR))\n",
    "        if (num + 1) % batch_size == 0:\n",
    "            hr_data = img_to_one(np.array(batch_hr_img_data, dtype=\"float32\"))\n",
    "            lr_data = img_to_one(np.array(batch_lr_img_data, dtype=\"float32\"))\n",
    "            batch_hr_img_data.clear()\n",
    "            batch_lr_img_data.clear()\n",
    "            yield hr_data, lr_data, f'{num} / {batch_size * batch_num + 1}'\n",
    "    batch_hr_img_data.clear()\n",
    "    batch_lr_img_data.clear()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a, b, _ = next(data_loader('../data/training_set/cats', 1))\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(a[0])\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(b[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "def show_pic(real_img, fake_img):\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(real_img[0])\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(fake_img[0])\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "bc = BinaryCrossentropy(from_logits=False)\n",
    "vgg19 = VGG19(include_top=False)\n",
    "vgg19.trainable = False\n",
    "dis_output_shape = (16, 16, 1)\n",
    "\n",
    "def content_loss(hr_img: Tensor, fake_hr_img: Tensor, d_preds: Tensor, batch_size: int):\n",
    "    hr_img = reverse_img(hr_img)\n",
    "    fake_hr_img = reverse_img(fake_hr_img)\n",
    "    hr_img = preprocess_input(hr_img)\n",
    "    fake_hr_img = preprocess_input(fake_hr_img)\n",
    "    hr_img_f = vgg19(hr_img)\n",
    "    fake_hr_img_f = vgg19(fake_hr_img)\n",
    "    return mean_squared_error(hr_img_f, fake_hr_img_f) + bc(ones(shape=(batch_size, *dis_output_shape)), d_preds)\n",
    "\n",
    "\n",
    "@function\n",
    "def train_step(hr_img: Tensor, lr_img: Tensor):\n",
    "    batch_size = hr_img.shape[0]\n",
    "    fake_hr_img = gen(lr_img)\n",
    "    img_set = concat([hr_img, fake_hr_img], axis=0)\n",
    "    img_label = concat([ones(shape=(batch_size, *dis_output_shape)), zeros(shape=(batch_size, *dis_output_shape))], axis=0)\n",
    "    img_label += 0.05 * random.uniform(img_label.shape)\n",
    "\n",
    "    with GradientTape() as dis_G:\n",
    "        d_preds = dis(img_set)\n",
    "        d_loss = bc(img_label, d_preds)\n",
    "    d_gradiant = dis_G.gradient(d_loss, dis.trainable_weights)\n",
    "    dis_opt.apply_gradients(zip(d_gradiant, dis.trainable_weights))\n",
    "\n",
    "    with GradientTape() as gen_G:\n",
    "        g_preds = gen(lr_img)\n",
    "        d_preds = dis(g_preds)\n",
    "        g_loss = content_loss(hr_img, g_preds, d_preds, batch_size)\n",
    "    g_gradiant = gen_G.gradient(g_loss, gen.trainable_weights)\n",
    "    gen_opt.apply_gradients(zip(g_gradiant, gen.trainable_weights))\n",
    "\n",
    "    return d_loss, g_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12364/76842578.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[0mshow_pic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_img\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgen_pic\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12364/76842578.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mhr_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata_loader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'../data/training_set/cats'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m             \u001B[0md_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mg_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhr_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m             print(f'\\r{epoch=}--{info}--d_loss={d_loss.numpy()}',\n\u001B[0;32m     11\u001B[0m                   end='', flush=True)\n",
      "\u001B[1;32md:\\vnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    883\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    884\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 885\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    886\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    887\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\vnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    948\u001B[0m         \u001B[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    949\u001B[0m         \u001B[1;31m# stateless function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 950\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    951\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    952\u001B[0m       \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfiltered_flat_args\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\vnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3037\u001B[0m       (graph_function,\n\u001B[0;32m   3038\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3039\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   3040\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   3041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\vnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1961\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1962\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1963\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1964\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1965\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32md:\\vnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    589\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    590\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 591\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    592\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    593\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\vnv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    epochs = 2000\n",
    "    batch_size = 32\n",
    "    test_img = cv2.cvtColor(cv2.resize(cv2.imread('../data/training_set/dogs/dog.1.jpg', cv2.IMREAD_COLOR), (32, 32), cv2.INTER_LINEAR), cv2.COLOR_BGR2RGB)\n",
    "    test_img = img_to_one(test_img)\n",
    "    test_img = np.expand_dims(test_img, axis=0)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for hr_data, lr_data, info in data_loader('../data/training_set/cats', batch_size):\n",
    "            d_loss, g_loss = train_step(hr_data, lr_data)\n",
    "            print(f'\\r{epoch=}--{info}--d_loss={d_loss.numpy()}',\n",
    "                  end='', flush=True)\n",
    "        print()\n",
    "\n",
    "        gen_pic = gen(test_img)\n",
    "        show_pic(test_img, gen_pic)\n",
    "\n",
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}